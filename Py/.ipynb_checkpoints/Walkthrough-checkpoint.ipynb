{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 - Parse Data\n",
    "The datasets within the _datasets_ folder are nothing but pickled dictionaries of lists of numpy objects and other lists.\n",
    "\n",
    "Use the *parse_mts_dataset* function in *mts_dataset_parser.py* to import them.\n",
    "\n",
    "If you want, you can use your own dataset but it is advised that you bring it to the following format:\n",
    "\n",
    "* **mts_list:** a list that contains MTS objects which are size MxT numpy arrays.\n",
    "* **dmts_list (optional):** first difference of the MTS objects in mts_list in the same order \n",
    "* **labels_list:** labels for the given MTS objects in the same order\n",
    "* **train_index:** list of indices to extract train instances from mts_list or dmts_list or labels_list\n",
    "* **test_index:** same as above, just the test indices\n",
    "* **num_attributes:** number of attributes in any given MTS object.\n",
    "\n",
    "Note that *train_index* and *test_index* are for the predefined test-train split that are commonly being used for research purposes. The whole dataset could be random shuffled with for another test-train split of desired sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from mts_dataset_parser import parse_mts_dataset\n",
    "\n",
    "\"\"\"\n",
    "You can change the \"file\" var to try a different dataset in the selection\n",
    "Or import your own dataset externally\n",
    "Do not change the \"dirname\" var to work locally\n",
    "\"\"\" \n",
    "dirname = \"../data\"\n",
    "file = \"scaled_Uwave_mts.p\"\n",
    "\n",
    "with open( os.path.join( dirname , file ) , 'rb' ) as infile:\n",
    "    data = pickle.load( infile )\n",
    "( mts_list , dmts_list , train_index , test_index , labels_list , num_attributes) = parse_mts_dataset( data )\n",
    "labels_train = labels_list[train_index]; labels_test = labels_list[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Import IMPHD and Extract Features\n",
    "The *im-phd.py* file includes the class *IMPHD* that mainly wraps the feature extractor of the method. \n",
    "\n",
    "First, define the values of lambdas and betas that you would like to extract features for in variables *list_lambdas* and *list_betas*. Use the *extract_features* method that extracts and stores the features for all mts in the *mts_list* for the parameter grid produced by the values in *list_lambdas* and *list_betas*. \n",
    "\n",
    "If *dmts_list* is not provided, the method automatically computes that too. In this example however, it is precomputed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full combination set is being used\n",
      "**** -------------------------------------- ****\n",
      "IM features are being computed for the following lambda values:\n",
      "[5, 10, 15]\n",
      "**** -------------------------------------- ****\n",
      "PHD features are being computed for the following beta values:\n",
      "[0, 0.025, 0.05]\n",
      "**** -------------------------------------- ****\n"
     ]
    }
   ],
   "source": [
    "from im_phd import IMPHD\n",
    "list_lambdas = [ 5 , 10 , 15 ]\n",
    "list_betas = [ 0 , 0.025 , 0.05 ]\n",
    "imphd = IMPHD()\n",
    "imphd.extract_features( mts_list=mts_list, num_attributes=num_attributes , list_lambdas=list_lambdas\n",
    "                       , list_betas=list_betas, dmts_list=dmts_list )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Find the Best Parameter Set Based on Out-of-Bag Scores\n",
    "\n",
    "For multiple values of lambdas and betas, a parameter grid is already defined. In order to find the best parameter set, out-of-bag score is utilized as the classifier is a random forest and such an approach is allowed. The *ParameterGrid* functionality of Sci-kit Learn package could be used for setting up the parameter optimization. At each point in the grid (i.e. for each parameter pair) a classifier is fit and desired score is compared to the currently best score to find the best performing parameter pair. The best performing parameter pair in the training split may not be the best performing for the test split. It is shown within the thesis however that train errors over the parameter grid is consistent with the actual error on the test data.  \n",
    "\n",
    "User can also work with another classifier such as SVM or GradientBoostingClassifier since the features are readily available in the imphd instance. In such a case, parameter optimization requires another procedure such as a K-Fold Cross Validation.\n",
    "\n",
    "At any time, the *get_feature_set* method should be used for retrieving the feature set for a specific parameter tuple. It requires two parameters: with num_intervals keyword  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# Initialize random forest parameters and the classifier\n",
    "n_trees=100; n_jobs=-1; random_seed=42;\n",
    "rf = RandomForestClassifier( oob_score = True , n_estimators = n_trees , n_jobs = n_jobs , random_state = random_seed )\n",
    "\n",
    "# Create a parameter grid based on the list of lambdas and betas provided, this step can be adjusted \n",
    "# as long as the features are readily extracted in the IMPHD class\n",
    "pg = ParameterGrid( {'num_intervals':list_lambdas , 'radius_cut':list_betas} )\n",
    "best_score = -1\n",
    "for params in list( pg ):\n",
    "    # Use get_feature_set method to retrieve specific feature set per parameter tuple\n",
    "    feature_set = imphd.get_feature_set( **params )[train_index]\n",
    "    rf.fit( feature_set , labels_train )\n",
    "    # Update the best model if the incoming score is better\n",
    "    if rf.oob_score_ > best_score:\n",
    "        rf_best = copy.copy(rf)\n",
    "        params_best = params\n",
    "        best_score = rf.oob_score_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Predict test indices and report results\n",
    "In order to predict labels for the incoming mts objects, simply use the predict method of the trained classifier as the features are readily available from the feature extraction section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.95      0.98      0.97       437\n",
      "        2.0       0.98      1.00      0.99       452\n",
      "        3.0       0.97      0.98      0.97       454\n",
      "        4.0       0.97      0.95      0.96       450\n",
      "        5.0       0.91      0.97      0.94       433\n",
      "        6.0       0.97      0.88      0.92       449\n",
      "        7.0       0.98      0.98      0.98       447\n",
      "        8.0       0.98      0.99      0.98       460\n",
      "\n",
      "avg / total       0.97      0.97      0.97      3582\n",
      "\n",
      "The overall accuracy is:\n",
      "0.965661641541\n"
     ]
    }
   ],
   "source": [
    "features_test = feature_set = imphd.get_feature_set( **params_best )[test_index]\n",
    "predicted_labels = rf_best.predict( features_test )\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "print( classification_report( labels_test, predicted_labels ) )\n",
    "print(\"The overall accuracy is:\")\n",
    "print( accuracy_score( labels_test , predicted_labels ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miscellaneous\n",
    "### Extract features for a single instance\n",
    "The method *extract_features_for_single_instance* works pretty much the same as *extract_features* method only that it works for a single instance and does not only store the feature internally but immediately returns it. This method will be useful for production mode.\n",
    "\n",
    "### Random reduced comination generator\n",
    "The user is able to provide the model a custom combinations list. However for a quick trial, the *random_reduced_combination_generator* method will divide *num_attributes* dimensions into groups of *num_reduced_subsets* and only retrieve their 2-combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(9, 0),\n",
       " (9, 6),\n",
       " (0, 6),\n",
       " (10, 1),\n",
       " (10, 2),\n",
       " (1, 2),\n",
       " (7, 11),\n",
       " (7, 5),\n",
       " (11, 5),\n",
       " (4, 8),\n",
       " (4, 3),\n",
       " (8, 3)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Immediately after running parts 1 and 2 run here for a cross-check\n",
    "assert np.all( imphd.get_feature_set( **params_best )[0] == imphd.extract_features_for_single_instance( mts_list[0] , **params_best ) ), \"Oops! The method is not working properly\"\n",
    "\n",
    "# Print a sample reduced combination\n",
    "imphd.random_reduced_combination_generator( num_attributes=12 , num_reduced_subsets=3 , random_seed=10 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
